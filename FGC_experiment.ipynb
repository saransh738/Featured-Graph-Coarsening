#saransh code
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0145e5",
   "metadata": {},
   "source": [
    "# FGC Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c4059",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace42d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeprobust in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: torchvision>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (0.12.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (2.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (0.24.1)\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (1.11.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (8.2.0)\n",
      "Requirement already satisfied: gensim<4.0,>=3.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (3.8.3)\n",
      "Requirement already satisfied: texttable>=1.6.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (1.6.4)\n",
      "Requirement already satisfied: numba>=0.48.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (0.53.1)\n",
      "Requirement already satisfied: scikit-image>=0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (0.18.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (3.3.4)\n",
      "Requirement already satisfied: tensorboardX>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (2.5)\n",
      "Requirement already satisfied: tqdm>=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.17.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deeprobust) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.8->deeprobust) (0.29.14)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.8->deeprobust) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.8->deeprobust) (6.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->deeprobust) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->deeprobust) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->deeprobust) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.1->deeprobust) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from networkx>=2.4->deeprobust) (5.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba>=0.48.0->deeprobust) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba>=0.48.0->deeprobust) (0.36.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.0->deeprobust) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.0->deeprobust) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-image>=0.0->deeprobust) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.1->deeprobust) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.1->deeprobust) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboardX>=2.0->deeprobust) (3.17.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.2.0->deeprobust) (3.7.4.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision>=0.4.0->deeprobust) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4.0->deeprobust) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4.0->deeprobust) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4.0->deeprobust) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4.0->deeprobust) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install deeprobust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3a42d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'torch_sparse'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\deeprobust\\graph\\data\\__init__.py:9: UserWarning: Please install pytorch geometric if you would like to use the datasets from pytorch geometric. See details in https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
      "  warnings.warn(\"Please install pytorch geometric if you \" +\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "from deeprobust.graph.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fa0d5",
   "metadata": {},
   "source": [
    "# Real Datasets Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e87ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'cora' #other datatsets : 'citeseer' , 'polblogs' , 'acm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d18ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_nodes = 2708 #original number of nodes.\n",
    "## citeseer : 3312\n",
    "## cora     : 2708\n",
    "## polblogs : 1490\n",
    "## acm      : 3025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188b1d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading polblogs dataset...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "[[26. -1.  0. ...  0.  0.  0.]\n",
      " [-1. 45.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  1. -1.  0.]\n",
      " [ 0.  0.  0. ... -1. 18.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(root='', name=dataset_name, setting='gcn',seed=10)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "A = np.array(adj.todense())\n",
    "X=np.array(features.todense())\n",
    "np.save(\"A.npy\", A)\n",
    "print(A)\n",
    "#np.save(\"X.npy\", X)\n",
    "print(X)\n",
    "import numpy as np\n",
    "b=np.ones(ori_nodes)\n",
    "\n",
    "z=A@b\n",
    "D=np.diag(z)\n",
    "L=D-A\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9024e",
   "metadata": {},
   "source": [
    "##### RUN BELOW CELL ONLY FOR POLBLOGS AS FEATURES NEED TO CREATED FOR POLBLOGS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bba8c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "X = np.random.multivariate_normal(np.zeros(1490), np.linalg.pinv(L), n).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b3436",
   "metadata": {},
   "source": [
    "#### Minnesota, Airfoil and Bunny datasets have been taken from pygsp library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsp as gsp\n",
    "from pygsp import graphs\n",
    "G=graphs.Airfoil()\n",
    "print(G.N)\n",
    "L=G.L.toarray()\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7f86d",
   "metadata": {},
   "source": [
    "# Creating Synthetic Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Input parameters.\n",
    "p=1000 # number of nodes\n",
    "param = 0.1  \n",
    "#graph = erdos_renyi_graph(p, param, directed = False)\n",
    "#graph = nx.barabasi_albert_graph(n=p,m=20)\n",
    "#graph = watts_strogatz_graph(p,20,param,seed=12)\n",
    "graph=nx.random_geometric_graph(p,param)\n",
    "\n",
    "\n",
    "# DISPLAY GENERATED GRAPH.\n",
    "print(graph.edges)\n",
    "print(graph.nodes)\n",
    "# PLOTTING GENERATED GRAPH.\n",
    "nx.draw(graph, with_labels = True)\n",
    "plt.title(\"Laplacian\")\n",
    "plt.show()\n",
    "# CREATING EDGE WEIGHTS.\n",
    "W = np.zeros((p, p))\n",
    "for (x, y) in graph.edges:\n",
    "    W[x][y] = np.random.randint(1,10)       #weight of edge between x and y\n",
    "W_t = W + W.T\n",
    "# CALCULATING LAPLACIAN MATRIX OF GENERATED GRAPH.\n",
    "L = np.diag(W_t@np.ones((W_t.shape[0]))) - W_t\n",
    "print(L)\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Fetures for any synthetic graph:\n",
    "n = 5000 # number of features of each node.\n",
    "X = np.random.multivariate_normal(np.zeros(p), np.linalg.pinv(L), n).T\n",
    "X.shape\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0eae1",
   "metadata": {},
   "source": [
    "# FGC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da57719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver_v2:\n",
    "\n",
    "  def __init__(self, X, k, lambda_param, beta_param, alpha_param, gamma_param):\n",
    "    self.X = X\n",
    "    self.p = X.shape[0]\n",
    "    self.k = k\n",
    "    self.n = X.shape[1]\n",
    "    \n",
    "    n = self.n\n",
    "    k = self.k\n",
    "    p = self.p\n",
    "    \n",
    "    self.thresh = 1e-10 # The 0-level\n",
    "\n",
    "    # Basic initialization (Completely random)\n",
    "    self.X_tilde = np.random.normal(0, 1, (k, n))\n",
    "    \n",
    "    self.C = np.random.normal(0,1,(p,k))\n",
    "    self.C[self.C < self.thresh] = self.thresh\n",
    "    \n",
    "    self.w = np.random.normal(10, 1, (k*(k-1))//2)\n",
    "    self.w[self.w < self.thresh] = self.thresh\n",
    "\n",
    "\n",
    "    # Model Hyperparameters\n",
    "    self.beta_param = beta_param\n",
    "    self.alpha_param = alpha_param\n",
    "    self.lambda_param = lambda_param\n",
    "    self.gamma_param = gamma_param\n",
    "    self.iters = 0\n",
    "    self.lr0 = 1e-5\n",
    "\n",
    "  def getLR(self):\n",
    "    a = 0.99\n",
    "    return self.lr0\n",
    "\n",
    "  def calc_f(self):\n",
    "    \n",
    "    #w = self.w\n",
    "    X_tilde = self.X_tilde\n",
    "    beta_param = self.beta_param\n",
    "    #Lw = self.L_operator(w)\n",
    "    #L = np.load('L (5).npy')\n",
    "    fw = 0\n",
    "\n",
    "    fw += np.trace(X_tilde.T@self.C.T@L@self.C @X_tilde)\n",
    "    # Added the tr(X.T L X) term\n",
    "   # fw += ((beta_param*(np.linalg.norm(Lw)**2))/2)\n",
    "    # Added the Frobbenius norm term\n",
    "    J = np.outer(np.ones(self.k), np.ones(self.k))/self.k\n",
    "    fw -= self.gamma_param*np.linalg.slogdet(self.C.T@L@self.C + J)[1]\n",
    "    # Added the log_det term\n",
    "    fw += (self.alpha_param/2)*(np.linalg.norm(np.subtract(self.X, np.dot(self.C, self.X_tilde))))**2\n",
    "    # Added l2 norm || X - C*X_tilde ||\n",
    "    fw += (self.lambda_param)/2*((np.linalg.norm(np.dot(self.C, np.ones((self.k, 1)))))**2)\n",
    "    # Added L_1,2 norm || C ||\n",
    "    return fw\n",
    "\n",
    "  def update_X_tilde(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    L_tilde = self.C.T@L@self.C\n",
    "    A = 2*L_tilde/(self.alpha_param)\n",
    "    A = A + np.dot(self.C.T, self.C)\n",
    "    b = np.dot(self.C.T, self.X)\n",
    "    # Update 1\n",
    "    self.X_tilde = np.linalg.pinv(A)@b\n",
    "\n",
    "    # Update 2\n",
    "    # lr = self.getLR()\n",
    "    # self.X_tilde = self.X_tilde - lr*self.alpha_param*(A@self.X_tilde - b)\n",
    "\n",
    "    # #new update:\n",
    "    for i in range(len(self.X_tilde)):\n",
    "      self.X_tilde[i] = (self.X_tilde[i]/(np.linalg.norm(self.X_tilde[i])))\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "  def grad_C(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    J = np.outer(np.ones(k), np.ones(k))/k\n",
    "    v=np.linalg.pinv(self.C.T@L@self.C + J)\n",
    "    gradC = np.zeros(self.C.shape)\n",
    "    gradC += self.alpha_param*((self.C@self.X_tilde - self.X)@self.X_tilde.T)\n",
    "    gradC += (self.lambda_param) * (np.abs(self.C) @ (np.ones((self.k, self.k))))\n",
    "    gradC += -2*(self.gamma_param)*L@self.C@v\n",
    "    gradC += 2*L@self.C@self.X_tilde@self.X_tilde.T\n",
    "    \n",
    "    return gradC\n",
    "\n",
    "  def update_C(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    C = self.C\n",
    "    C = C - lr*self.grad_C()\n",
    "    C[C<self.thresh] = self.thresh\n",
    "    self.C = C\n",
    "    C = self.C.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "      C[i] = C[i]/np.linalg.norm(C[i],1)\n",
    "\n",
    "    self.C = C.copy()\n",
    "    return None\n",
    "\n",
    "  \n",
    "  def fit(self, max_iters):\n",
    "    ls = []\n",
    "    MAX_ITER_INT = 100\n",
    "    for i in tqdm(range(max_iters)):\n",
    "      #for _ in range(MAX_ITER_INT):\n",
    "        #self.update_w()\n",
    "      for _ in range(MAX_ITER_INT):\n",
    "        self.update_C(1/self.k)\n",
    "      # for _ in range(MAX_ITER_INT):\n",
    "      self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      #print(self.C@self.C.T)\n",
    "      #print()\n",
    "\n",
    "    return (self.C, self.X_tilde, ls )\n",
    "\n",
    "  def New_fit(self):\n",
    "    ls=[]\n",
    "    MAX_ITER_INT = 100\n",
    "    while(True):\n",
    "      C_prev=self.C\n",
    "      self.update_C(1/self.k)\n",
    "      self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      if(np.linalg.norm(self.C-C_prev)<0.1): # we have set the threshold for stopping criteria as 0.1.\n",
    "          return (self.C, self.X_tilde, ls )      \n",
    "    return (self.C, self.X_tilde, ls )    \n",
    "\n",
    "  def set_experiment(self, X, X_t):\n",
    "    self.X = X\n",
    "    self.X_tilde = X_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd6467",
   "metadata": {},
   "source": [
    "FGC has only 3 hyperparameters lambda, alpha and gamma. beta is not any hyperparameter (it is of no use), you can put it equal to any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Below shown for Cora.\n",
    "k = 812 # Coarsened graph's number of nodes i.e. k = r*ori_nodes\n",
    "overall_loss = []\n",
    "iterations = 10 # Number of iterations our objective function will run.\n",
    "#print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "# Hyperparameters: lambda, beta, alpha, gamma\n",
    "obj = solver_v2(X, k, 500, 0, 500, X.shape[1]/2) \n",
    "C_0, X_t_0, loss_ls = obj.fit(iterations)\n",
    "overall_loss.extend(loss_ls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7683226",
   "metadata": {},
   "source": [
    "Note: If you want to work with mentioned stopping criteria from the paper, then you can use obj.New_fit() in place of obj.fit(). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ebca5",
   "metadata": {},
   "source": [
    "### In below cell, we are computing REE and DE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4f2d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eigen_error \n",
      "(0.09344485166350994+0j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30670.12849126975\n",
      "6113760.193609843\n",
      "1219.5608020877253\n"
     ]
    }
   ],
   "source": [
    "eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "\n",
    "s=np.sort(eigen_values)\n",
    "\n",
    "eigen_value,eigenvector=np.linalg.eig(C_0.T@L@C_0)\n",
    "\n",
    "z=np.sort(eigen_value) \n",
    "\n",
    "\n",
    "s_new=s[-100:]\n",
    "z_new=z[-100:]\n",
    "\n",
    "temp=0\n",
    "for j in range(len(s_new)):\n",
    "  temp=temp+(abs(z_new[j]-s_new[j])/s_new[j])\n",
    "eigenerror=temp/len(s_new)\n",
    "print(\" eigen_error \")\n",
    "print(eigenerror)\n",
    "\n",
    "plt.plot(s_new, label=\"original\")\n",
    "plt.plot(z_new, label=\"coarsened\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(np.trace(X_t_0.T@C_0.T@L@C_0@X_t_0))\n",
    "print(np.trace(X.T@L@X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859d8f7",
   "metadata": {},
   "source": [
    "### Below, we are plotting heat map of C^TC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab94c4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAEFCAYAAAA2b4amAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxI0lEQVR4nO2de5wcVZn3v79JIDMTMkm4BAIJCyqIECFKjLwCS0TALCJEBRd8dXH1XXQXvK2oZFkVdtddRAR1vS0qiMpFDMIit3BZEVG5JiEkJMp1IRAJl4QkTAIk87x/nNOkUumZqe6u7q7ufr7zOZ+pOvXUqae6u54+/ZznOUdmhuM4jtNcupqtgOM4juPG2HEcpxC4MXYcxykAbowdx3EKgBtjx3GcAuDG2HEcpwDUzRhLminpj5IeknRava7jOI7TDqgeccaSRgB/Ag4HlgF3AyeY2QO5X8xxHKcNqFfPeDrwkJk9YmYvA5cBx9TpWo7jOC1PvYzxLsATif1lse5VJJ0k6R5J93zrW581wIsXM9vQdB28FL7UjCTLWvK4XhZG1qldlanb7KbM7Hzg/HLHnM5FqtdH0nGKTb0++cuAyYn9ScBTdbqW4zhORXR1dTdbhS2ol5vibmAPSbtL2ho4Hrg668n9/QvqpJZTNMw2NFsFpwPp6hqZuTSKulzJzDZIOgWYC4wALjCzxVnP7+2dSn//PfT2TquHek6BcLdE+2C2oWXezyLqWZfQtiooq4QbZKdTaSXD1gTKjUlVxKhRO2Q2fC+99EzN18tCod9tN8ROp+KGuL4U8fX1dGjHcToOaWTmMnxbmizp15KWSFos6VOx/gxJT0paEMuRQ7VT9deDpMnAT4CdgAHgfDP7pqSvAe8GXgYeBv7WzFZVe500y3+/NxPf5ol8juNUz4gRuUZTbAA+a2bzJI0B7pV0Uzx2npmdk6WRWnrGJQXeABwAnCxpb+AmYIqZ7UtIiZ5dwzW2YOLbHmD16pvzbNIpOB5xURza5b3Is2dsZsvNbF7cXgMsIZXkloWqjfFgCpjZjbbpHbuDEGOcK319h7H8oY/m3axTUIro3+tU2uW9qMQYJ7OFYzlp8Ha1G/Am4M5YdYqkhZIukDR+KJ1y8RmXUaDER4DrBznn1Rs8//zzy4kMycTX/Yj+/nsqPs9xHKcSY2xm55vZtEQpa7AkbQNcAXzazFYD3wNeC0wFlgNfH1KnWkPbogK/Ab5iZr9M1J8OTAPea8NfpGolVq++mb6+wzY15CFBjtPu1BxqNn78WzLbnJUr7x72epK2Aq4B5prZuWWO7wZcY2ZTBmujJqsVFbgCuDhliE8EjgLekcEQ10TSEIdruyF2HGdo8kyHliTgR8CSpCGWNNHMlsfd9wCLhmqnlmiKwRSYCXwBOMTM+qtt33Ecp17k3Gk7EPgQcL+kBbHun4ATJE0l/PJ/DPjYkDpV23GVdBDwW+B+QmhbSYFvAaOA52LdHWb28WGaq7r3nHZL9PcvoLd3arXNOY5TfGp2U+yww+GZbc4zz9xU7Aw8M7ud8i/KddWrUznpb7je3qm88MI1jB17VCPVaBjuE3ec2mnkBEBZacsMvLFjj2LduiHdMy2LG2LHqZ0844zzom2f7J6eQQctHcfpcIrYqam5ZyxphKT5kq5J1Z8aly3ZvtZrOI7j5ElXV3fm0ijy+Hr4FCH7rq9UEeetOBx4PIf2c2HdukXeW3YcB2hDn7GkScC7gB+mDp0HfJ4CrW3X0zOFFSu+3bTrt0tOv9NY/HNTH4roM67VTfENgtEthbYh6WjgSTO7b6gTa02HroYJE05h7drbG3KtNEXyUfkD3joU6XPTThTRGNeS9HEUsMLM7pU0I9b1AqcDRwx3frNWh95mm4MadanC4g+40+kU8RmoRaMDgaPjhMndBJ/xT4HdgftCgh6TgHmSppvZn2tV1nEcJw/ayhib2WziXMWxZ3yqmb0vKSPpMWCamT1bvYr1Zf36pXR379VsNRzHaSA5Ty6fC22Z9FEJJUO8atVVzVXEcZyG0VY+4yRmditwa5n63fJovxGMGzfLe8mO0yEU0U3R8T3jJN3dexVqwnqPenCc+lDEnnGtccbjJM2RtDSujPp/Yv0nJP0xrpR6dj6qNobe3mlNjUdOUsRvb8dpB7oq+GsUtT7t3wRuMLNjJW0N9Ep6O3AMsK+ZvSRpQs1aNpgJE05ptgqO49SRrgJOy1NLnHEf8JfAhwHM7GXgZUl/D5xlZi/F+hU56Ok4jpMbKqCHthaNXgM8A1wYJwr6oaTRwJ7AwZLulPQbSW/JRdMm0t+/oNkqOA4AAwPrm61CWyC6MpdGUcuVRgJvBr5nZm8CXgROi/XjgQOAzwGXxyWaNqMZ6dDV0ts7leX3vbPZajhOQ2cRy4OiDkK3m894GbDMzO6M+3MIxngZ8Mu4EOldkgaA7Qm96FdpVjp0tUzcby7Lr5vAxCPd6+I4WSnqIHRbuSlievMTkl4fq94BPABcBRwKIGlPYGugsBl4leCG2HHagyK6KWr92voEcHGMpHgE+FuCu+ICSYuAl4ETrdpVTx3HcepAW0VTAJjZAmBamUMfrKXdVmH57a9l4kEPDynjC4g6TvFopC84K8XTqIWYeNDDPP30OUPKuCF2nOJRRDeFG+Ma2XHHU32SoTag2aP+RQ9Za/brkzdtZ4wlfSamPC+SdKmkbklTJd0haUEMXZuel7JFZdy4Wc1WwamRZv+CKXrIWrNfn7xpK2MsaRfgk4T5iqcAI4DjgbOBM81sKvCluO8UkHbr7ThOVtrKGEdGAj0KX5u9wFOEmOHSStFjY11H8fzzlzVbhUy0W2/HKSZF/NIfwcjMpVHUEmf8JHAO8DiwHHjBzG4EPg18TdIT8fjscue3UgZepWy77fGsW7eo2Wo4TiEo4pd+EXvGtUwUNJ4wO9vuwCrgF5I+CEwHPmNmV0h6P/Aj4LD0+a2WgVeOocLWenqmAKGXvO22xzdSLcdxhqGtMvAIBvZRM3vGzF4Bfgm8DTgxbgP8gmCc25Is3/jeS3ac4lHEnnEtV3ocOEBSb5wI6B3AEoKP+JAocyjwYG0q5kezfFc9PVNYvfrmplzbcZwtaauJgszsTklzgHnABmA+we0wH/hmHNRbD5yUh6J50EzfVV/fFp4ax3GaRDumQ38Z+HKq+nZg/1radToPTxt3Gkm7+YydGvCsvc1xQ+w0kjx9xpImS/p1XAd0saRPxfptJd0k6cH4f/xQ7bgxbhLjxs1i+bwZzVbDcTqSnH3GG4DPmtkbCItqnCxpb8L87reY2R7ALXF/CJ2GQdIFklbEKTFLdcfFb4ABSdNS8rMlPRRXh/blMYZg4ptv9SWdHKcJ5NkzNrPlZjYvbq8hBDLsQgj9vSiKXQTMGqqdLGb/x8DMVN0i4L3AbcnK+G1wPLBPPOe7kkZkuEbH0ts7tdkqOE7HUYkxTiaoxTJoUIKk3YA3AXcCO5rZcggGG5gwlE7DOurM7LZ4gWTdknjhtPgxwGVxZehHJT1EiDP+w3DXcRzHaRSVRFOkEtQGRdI2wBXAp81sdRn7OIxO+bIL8ERif1ms24J2ToeuBXdbOE79yTvOWNJWBEN8sZmVkt6eljQxHp8IDLluW95D2OW+CsqmOrdDOnQ96O2dyrp1i15Np3YcJ39U1lRV2VboAv8IWGJm5yYOXU3ISD4r/v/vodrJu2e8DJic2J9EB87aVis9PVN44YVrmq2G47QtIzSQuWTgQOBDwKFxHvcFko4kGOHDJT0IHB73ByXvnvHVwCWSzgV2BvYA7sr5Gh3B2LFHNVsFx2lbushkZDNhZrdT3isAYZqITAxrjCVdCswAtpe0jJBx9zzwn8AOwLWSFpjZO81ssaTLgQcIsXcnm9nGrMo4juM0gq1UvDmWZVYId20hlCgyK1Z8gwkTPt1sNRynCNTs8P3AG67LbHMuWXJkfg7mIfAMvBZhwoRPs3LlnIrOKeIKC45TBLo0kLk0TKfhBAbJwPtXSQujo/pGSTvH+sMl3Svp/vj/0HoqPxjtaoTGjz+W1atvyCzv8z04TnlGMJC5NIpqM/C+Zmb7xkVHryEsPArwLPBuM3sjIZTjpznpWRHtbIT6+sJb4fHIjlM9LdkzNrPbCAN2ybrVid3RRJ+vmc03s1Io22KgW9KonHR1EvT2TvWZ3xynSorYM65lDbyvAH8DvAC8vYzI+4D5MTXaqQPjxs1qtgqO05IUMZqiltWhTzezycDFwCnJY5L2Ab4KfGyw8z0d2nGcZtHFQObSKPJwrl4CXEtc8UPSJOBK4G/M7OHBTvJ06Pzp71/gs8A5TgYa6QvOSlU9Y0l7JHaPBpbG+nEEwzzbzH5Xs3ZORfT2TmXNmlubrYbjFJ4i+oyzhLZdSpgC8/WSlkn6KHCWpEWSFgJHAJ+K4qcArwO+mMjRHnIOTydfxoyZ4QbZcYahiG4Kz8BzWpaBgfV0dXU3Ww2n8dScEfe5fX+c2eZ8beGHG5KB174BuS2AG5Pa8NfOqZaR7RRN4dROo4zJ+vVLG3Idx2kVWtVnXC4d+gxJT6bm7kyes6uktZJOrYfSTmV0d+/Fn/885FSqjtNRFNFnXG06NMB5ZjY1luvSx4Dra1XOyY+ddjrNJ6x3nEjOk8vnQlULkg6FpFnAI8CL1avl1AOfsN5xAo3s8WalFp/xKXHmtgskjQeQNBr4AnDmcCd7Bp7jtD9FnUFxK23IXBpFtdEU3wP+lRCS9q/A14GPEIzweWa2drhlqj0Dr/msXn0zfX2HNVsNp40p6gyKRewZV/VKmdnTpW1JPyBMownwVuBYSWcD44ABSevN7Nu1KurkT1/fYaxZcytjxsxotiqO01CKmA5dlTGWNNHMlsfd9wCLAMzs4ITMGcBaN8TFZsyYGRXNaWG2obC9HcfJSiND1rJS7YKkMyRNJbgXHmOI2dmc4lPJ5EJuiP0LqR1oyZ6xmZ1QpvpHGc47oxqFHKfouCFufVqyZ+w4jtNuFHFyeTfGjuN0HF1sbLYKW1BtOvTPE6nQj0lakDi2r6Q/SFocV4n22VxaGF/41GlHWjIDj5AO/W3gJ6UKM/vr0rakrxPWwUPBmfYz4ENmdp+k7YBX8lTYaSy9vVNZt24RPT1Tmq2K4+TGyAL2jGtKh1bI7Hg/cGisOgJYaGb3xXOfy0lPp4n09Exxg+y0FSMKaIxrnULzYOBpM3sw7u8JmKS5kuZJ+vxgJ3o6dGvhhthpJ0ZoY+bSKGodwDsBuDTV3kHAW4B+4BZJ95rZLekTPR3acZxmsbWK5z2t2hhH//B7gf0T1cuA35jZs1HmOuDNwBbG2HEcp1kU0Wdci5viMGCpmS1L1M0F9pXUG431IcADtSjoFBdfQcRpVUawMXNpFNWuDg1wPJu7KDCzlcC5wN3AAmCemV2bq8ZOYeju3ot16xYNL+gUhqJOadlo8vQZV7MaUtl2fHVop1bWr19Kd/dezVbD6RxqXq35pgM+mtnmHH7Hj4a8nqS/BNYCPzGzKbHuDMJEaedkvY5n4Dk1k7ch9ol4nHozKscBvEpXQxoMXx3aKRxuiJ16U4nPOBmGG8tJGS+zxWpIQ1FtOvR+MeX5fkm/ktQX67eSdFGsXyJpdkalnTbCU6iLifuLN1GJz9jMzjezaYmSJTHie8BrganAcsJqSENS7erQPwROM7M3AlcCn4v1xwGjYv3+wMfy6L47rUVv71SPtCgg/otjE/WOpjCzp81so5kNAD8Apg93zrDG2MxuA55PVb8euC1u3wS8ryQOjI5hbT3Ay8DqbOo77UR3915ukJ3CUu+JgiRNTOy+uhrSUFTrM14EHB23jwMmx+05wIuEbvnjwDlmljbkJWU9HbrN8QgLp6iMZGPmMhyDhP+eHd21C4G3A58ZXqfq+AjwLUlfAq4m9IAhdMU3AjsD44HfSrrZzB5JN+Dp0I7jNIut9fLwQhmpdjWkNNWuDr2UMEMbkvYE3hUPfQC4wcxeAVZI+h0wDdjCGDuO4zSLtpm1TdKE+L8L+Gfg+/HQ48ChCowGDgDccehsxtq1tzdbhUx49MEm2u21KOLk8tWmQ58g6U8EQ/sUcGEU/w6wDcGnfDdwoZktrIvmTsuyzTYHsWrVVc1WY1g8+mAT7fZa5OkzzgtPh3aahk9Y71RJzenQTx58SGabs8tvf1Pz9bJQyAy8dvtJ5JSnp2cKy+89uNlqOB1IESeXz+KmmCzp1zGjbrGkT8X6r0laGtP9rpQ0LnHObEkPSfqjpHdWqlS7/STqdIb6cp24/28bqInjBLbWK5lLo8jSM94AfNbM3kAYkDtZ0t6EZI8pZrYv8CdgNkA8djywDyFz77uSRtRDeac18C9Xp2gU0WecJQNvuZnNi9trgCXALmZ2o23q8twBTIrbxwCXmdlLZvYo8BDDpAK6W8Ip4fNaOI2gJSeXTxLnmXgTcGfq0EeA6+P2LsATiWPLYl26rVcz8H7wgwsqUcNpY3p7p7L8qTOarYbT5hTRZ5z596OkbYArgE+b2epE/ekEV8bFpaoyp28xcukZeM5gTNz5DPr7F9DbO7XZqjhtShGTPjIZY0lbEQzxxWb2y0T9icBRwDtsU4zcMjbNVQHBffFUPuo69aYoE7u7IXbqyVZdxXONZommECHPeomZnZuonwl8ATjazPoTp1wNHC9plKTdgT2Au/JV26kXRTDEjlNvrGsgc2kUWZ68A4EPAfdLWhDr/gn4FjAKuCnYa+4ws4+b2WJJlxNWhd4AnGxmxftN4LQUniDi5Il1ZfeMNiTjA8/Ac1qI1atvoK8vvc5B7RTFNZM3rXpfGfSu2T5unPnazDZnxA0Pd24GnuOUo69vJi+8cE3u7baiwcpCq95XI/S2LstcGkVrvltOS5FnD23s2KNyacfpcBpoZLNSdTp04vipkkzS9nH/cEn3xlnu75V0aL2Ud1qDVu2hOe3LwMiNmUujyPKUlNKh50kaA9wr6SYze0DSZOBwwjzGJZ4F3m1mT0maAsylTNKH4zhOs2ik+yErVadDx8PnAZ8nMQBnZvPNrBRXvBjoljQqV63rTD3Tsz31O38GBtbz4ot3NFsNp4Uoos+46nRoSUcDT5rZfUOc8j5gvpm9VKatwi5IWs+f1Z38k31gYH1d2u3q6mb06ANYuXJOXdp32pAuy14aRFXp0ATXxenEdfAGkd8H+OpgMp4O3Xl0dXXXtf3x44/1eOSCU5Rwu0Ymc2QlU8+4TDr0a4HdgfskPUZIeZ4naacoPwm4EvgbM3u4Hoo7Tjl6eqawbt2iZqvhDEIRDDHAwMiBzKVRDPvKlEuHNrP7gQkJmceAaWb2bJxk/lpgtpn9rh5KO85QeM/YGY6WHMBjUzr0oZIWxHLkEPKnAK8DvpiQnzCEvOM4TmMpoM/Y06GdtufFF+9g9OgDmq2Gkx81pyev+ch2mW3OmAue83Rox8mD0aMPqEsatdO6tHxom+O0KmPHHsWqVVc1Ww2nILSkMR4qHVrSJ+IK0IslnZ06b1dJayWdWg/Fnfaj3gkx48bNqmv7TutgIwcyl0ZRdTo0sCNh8dF9zeylMoN057FpXTzHGZaihD057U9LxhkPkQ7998BZpew6M1tROkfSLOARQjq00wA8zbpyyvmR/XXsDFrSTZEktTr0nsDBku6U9BtJb4kyownLMZ05TFuFTYduRbxXWTljxx7F+vVLN6vz17EzKKIxrnp1aIVP7XjgAOAtwOWSXkMwwueZ2dq4HFNZPB3aqZR6pNJ2d+/FypVzGD/+2FzbdYpNEZM+alkdehnwy7gq9F2SBoDtgbcCx8YBvXHAgKT1Zvbt3LV3Oop69VrdEHcgORpjSRcARwErzGxKrNsW+DmwG/AY8H4zWzmkShkuVHZ1aOAq4NAosyewNfCsmR1sZruZ2W7AN4B/L5Ihdp+g4zg5Ty7/YyC9OONpwC1mtgdwS9wfklrSoS8AXiNpEXAZcKIVJJ1vKNwn6AyHTzTU/uTpMzaz24DnU9XHABfF7YuAWcO1M6xlMrPbGTz98IPDnHvGcO07TtEoTTS0evXN9PUd1mRtnHrQAJ/xjma2HEJEWpb5eTwDz3EGoa/vsC2iLZw2oYKJgpKRX7GcVBeVhhMYLANP0lRJd0S3xT2SpifO2VfSH6L8/ZLqO6u449SJ7u69fF6LNsS6BrIXs/PNbFqiZInFfVrSRID4f8Uw8pl6xqUMvDcQwthOlrQ3cDZwpplNBb4U94khbz8DPm5m+wAzgFcyXMdxCsnYsUfR37+g2WpUjA9WD8FIZS/VcTVwYtw+EfjvYVUaTiD6PUq+jzWSShl4BvRFsbFAaRHSI4CFpbXxzOy5Cm7AcQpJb+/UZqtQMT5YPQRd+c2KKelSQqdze0nLgC8DZxFyLz4KPA4cN1w7Fb1bqQy8TwNzJZ1D6GG/LYrtCZikucAOwGVmdvaWrdVGUdbSchynBcnRGJvZCYMcekcl7WQewEtn4BHmpviMmU0GPkOIRYZg4A8C/m/8/x5JWyhVazq0G2KnmXj4W4vTpeylQWRa6SNm4F0DzC0lfkh6ARhnZhYTQ14wsz5JxwMzzezDUe6LwHoz+9oQlyh8fLLjpFmz5lbGjJnRbDU6kZot5PJzts5scyae+nIxVvoYIgPvKeCQuH0o8GDcngvsK6k3DuYdAjyQn8qOUwzGjJnhPeRWpauC0iCy/NYvZeDdL2lBrPsn4O+Ab0aDux44CcDMVko6F7ib0OO9zsyuzVtxxykCvhJ1izKyeCkWviCp4zitRu1uim/3ZHdTnLKuGG4Kx3Gys/y6YbNenSJQwAE8N8Y54QH2DsDEI1e0ZIJIx1FAn3GWAbxuSXdJui+mN58Z67eVdJOkB+P/8bF+K0kXxTToJZJm5610EQ2fh9o5JXp7p/rAXtFp0Z7xS8ChZrYfMBWYKekABp+v8zhglJm9Edgf+FhMFskNN3xO0fGBvYLTisbYAmvj7laxGIPP12nA6Bhl0QO8DKzOUedCUsTeutMc/LPQAozsyl4aRKYrSRoRw9pWADeZ2Z2k5usESiMXc4AXCfNZPA6cY2bpiZfbbkFS7607Jcp9FlatuqrxijiDU0CfcSYLYmYbgamSxgFXShrqN9h0YCOwM2HB0t9KutnMHkm16QuSOh3DuHGz6O+/h97eac1WxYGGuh+yUpHdN7NVwK2E9Z4Gm6/zA8ANZvaKma0Afgf4J9DpeEqG2Af3CkAr+owl7RB7xEjqAQ4DljL4fJ2PE9bLk6TRhDmQfbkEx4n09Ezx8LdmU0BjnMVNMRG4SNIIgvG+3MyukfQHys/X+R3gQmARIVPmQjNbmL/qjtO6lMLfPOqiSVQ/aXzd8HRox3FajdrToX+5XfZ06Pc+1xDL7SEAjuN0Hq0+gFdUBgbWN1sFx6mZFSu+3WwVaqKl4qsL6DOuJR36XyUtjKtD3yhp58Q5syU9JOmPkt5ZzxsA6Oryxaed1mfChFNYvfqGZqtRNfWOtc/V2LeiMWbwdOivmdm+cXXoawgrRBNXjj4e2IcQAvfdOPjnOM4w9PXN9ASRQcjV2Ldi0oeFEb4t0qHjOnglRrNpEO4YwiKkLwGPSnqIkAjyh9y0dpw2Zty4Wc1Wof0p4OTytaRDI+krkp4gLD76pSi+C/BE4vRlsS7dZlulQztOFlrKr9rOtKibAjPbGN0Rk4DppXRoMzs9rg59MXBKFC+n/RZhJGZ2vplNM7NpJ510UlXKO06rUc1P7aefPqcOmnQ4rWqMS6TSoZNcArwvbi8DJieOTSIsXuo4ThXsuOOpvPTSQ81Wo70ooM+46nRoSXskxI5mU8rz1cDxkkZJ2h3YA7grV60dp8MYNep1PrCXJxqRvTSIWtKhr5D0emAA+F/g4wBmtljS5cADwAbg5Djrm+M4NeADezlSwAAvT4cuKWAbOnZO4k6+d6c6mvyZqT0d+nd7Zk+HPvBPvjp0I+lkY9TJ997KNHNgr+U/MxqZvTSIWjLwzpD0ZMzAWyDpyFh/uKR744Kk90o6tN434TidyI47ntqQqThrDccrZDhfi/qMSxl4ayVtBdwu6fp47DwzS389Pwu828yeiiFwcykTZ+w4Tu309k7lued+zHbbfbhu16i1F1zL+QMD6+sz3UEBfcZVZ+ANIT8/sbsY6JY0KmbkOY6TMyVD3I7zI9dt3pmu4hnjmjLwgFPiZEEXSBpf5tT3AfPdEDtO/enpmeJLOmWla1T20iiVsggNkoH3PeC1hMmDlgNfT54jaR/gq8DHyrXp6dCOkz/t1jOuGy3qM34VM1sl6VZgZtJXLOkHhJnbSvuTgCuBvzGzhwdpy1eHdhynOeRsZCU9BqwBNgIbzKziRZhrycCbmBB7D2HNO6LstcBsM/tdpQo5jpMfK1Z8o9kqFJOuEdlLdt5uZlOrMcSQzU0xEfi1pIXA3QSf8TXA2TF8bSHwduAzUf4U4HXAFxNhbxOqUc5pDwoZ2tQhTJjwaVaunNNsNYpHAeOMPQPPcSqkFTMW2yzSovYMvIVHZrY5O+93/ceA5NSS50c36yaFpEeBlQRb9l/p41lorU+U4xSAVjPE4AN7W9C1dWbR1PjWYBwYcysmADdJWmpmt1WkUiXCjuM4bUHOPmMzeyr+X0EIXphesUrDCQyRDv3zhE/4sRiHnDxvV0lrJZ1aqVKO49SXjo9HztFnLGm0pDGlbeAIYkBDJVSdDm1mf51Q5uvAC6nzzgOux3GcwtHTM4X+/nvo7a1q4L/1yTe0bUfgSkkQbOolZlbxMt81p0MraPB+4NBE3SzgEeDFShVyHKcx9PZOY+XKOYwff2yzVWk8ORpjM3sE2K/WdmpNhwY4GHjazB6MsqOBLwBnDtOmZ+A5TpPpSEMMMGLr7KVBZBoWjit1TI0JHVdKmmJmJZ/ICcClCfEzCbO5rY3d9sHabMsMvLrNMuU4Tn4UMCKm6nRoYJFCjM97gf0TYm8FjpV0NjAOGJC03sy+nY/KxcYNsdPKtFk88uAUcArNqtOh4+HDgKVmtqwkb2YHm9luZrYb8A3g3zvFEDtOq9PTM4Xlv9+72WrUnxadKKjsgqTx2PFs7qJwHKfFmfi2B1i79na22eagZqtSPwrYM/Z0aMdxWo3a06Ef/2z2BUl3/bovSOo4ztA0YhKmtWtvr/s1Gk4BJ5cv3pBiwWjFSWGc9mG46JxGfDbb0l1RQDdFLenQ+0n6Q5xG81eS+hLn7BuPLY7HWzbEwA2x00w8OqdOFHAAL4ubopQOvR9hiaWZkg4AfgicZmZvJEyM8TmAGO72M+DjZrYPMAN4JX/VnVrwOYadalm16qpmq1A7BZzPeFhjbIFy6dCvB0pTxN1EWHwUwiQZC83svnj+czFpxCkQ3uN3qmXcuFk899yPm61GTUgjM5dGUUs69CLg6ChyHDA5bu8JmKS5kuZJ+vwgbXo6tOO0KNtt92FWr7652WpUTRGNcdXp0MBHgG9J+hJwNfByos2DgLcA/cAtku41s1tSbbZlOrTjdAp9fYc1W4WqKeIwVkWhbWa2CriVsDr0UjM7wsz2JyR+lFaBXgb8xsyeNbN+4Drgzfmp7DhO3nTaGEIRe8a1rA49IdZ1Af8MfD+eMhfYV1JvHMw7BHigUsU67cPhOJV85vN+PvIwOmvW3FpzG42iJY0xg68OfYKkPxHmqXgKuBDAzFYC50bZBcA8M7u2UsV8gMnpNCr5zBfx+RgzZkbL+JGLaIw9HdpxnFxZs+ZWxoyZUc9L1Jye/PzzP8tsc7bd9oMNSYcu3terMySeEegUnTob4lwo4gCeP9Uthhtix6mdIj5HmaMpYqzxfEnXxP3jYrrzgKRpCbmtJF0U06CXSJpdD8WLjA8+Oo2iFT5rRVyJuog+40pC2z4FLEnsLyKs8nFbSu44YFRMk94f+Jik3WpRstUo4reuszkDA+ubrUIutMJnradnCitXzmm2GpvRssZY0iTgXYT5KAAwsyVm9scy4gaMjmFtPYRkkNU56Oo4ueET8DSW8eOPLVgPeWQFpTFk7Rl/A/g8MJBBdg7wIrAceBw4x8yeTwt5OrTjdBY9PVMKE4tcxJ7xsFeSdBSwwszulTQjQ5vTgY3AzsB44LeSbjazR5JCng7tOJ1HUSItivjLKIvZPxA4WtKRQDfQJ+lnZvbBQeQ/ANxgZq8AKyT9DpgGPDKIvNOmeBheMRhugvpOpIifyyxTaM42s0lxtefjgf8ZwhBDcE0cqsBo4AA2rSbtdBBF/MB3Im6Iy9G6PuMtkPQeScuA/wNcK2luPPQdYBtCtMXdwIVmtrBmTR3HaVv6+xc09HpF9Bl7OrTjOIWgv38Bvb1Ts4jWnJ68fv3SzDanu3svXx3acZzOobd3asOWdCpiz7jqDLxE/amSTNL2ibrZkh6S9EdJ78xTYadzaYVsM6c2xo2b1ZDrSN2ZS6OoxOyXMvCSq0BPBg4nDNqV6vYmDPTtQwhvu1nSnr4OnlMrPiDo5EURP0tVZ+BFziMkgyT9L8cAl5nZS2b2KPAQIfbYcRynELSym+IbpDLwJB0NPFlaBTrBLsATif1lsc5xHKdilt+wY+5t5mmMJc2MLtmHJJ1WrU5Zll16NQMvUdcLnA58qdwpZeq2GLn0dGjHcbIwcebTuadR52WMJY0ghPP+FbA3YQWkvavRqaoMPOCnwO7AfZIAJgHzJE0n9IQnJ86fRFiWaTM8HdpxtsSzFsszZswMnnnm++yww8dzaS/HgbnpwEOl6R4kXUZw1Va87me1GXjvM7MJZrZbrF8GvNnM/gxcDRwvaZSk3YE9gLsqVaze+Mi8U0TcEA/ODjt8nPXr80nmzdFNkZtbNvc4YzNbDFxO+Ga4ATg5QySFJH2M4OIYsmSVG05WGlmXdquVbfb121VXv6/mXz9PXXNMwMikd9TpVZdqLCel2klT3S99MytEAe7JU67VZJt9/XbV1e+r+devl65FKITpIOYm9mcDs6tpyzPwHMdxquduYA9Ju0vamuDKvbqahtxB5TiOUyVmtkHSKcBcYARwgQVXbcUUyRhnjW+rJA6ulWSbff1KZJt9/XrJNvv69ZJt9vUrkW25OFczuw64rtZ2ijJrm+M4TkfjPmPHcZwC4MbYcRynALgxdhzHKQBNGcCTtBchZXAXQoD0U8DVZrYk5+tsZ2bPZZSdYGYr8ry+4zhOVhreM5b0BeAyQubKXYQ4PQGX1jLjkaSzShPcS5om6RHgTkn/K+mQlOy2qbIdcJek8ZK2Tcn2SfoPST+V9IHUse8mtsdGHZZKei6WJbFuXLX31a5I2lpxYpO4/3ZJn5X0VxnP/4chjm1Vpm77MnWS9FZJ71VY0/GtSZ1SsruW3kdJu0k6VtKUPO9rqHvy++oAmpCx8idgqzL1WwMPlqmfBvwa+BlhAqKbgBcIRvxNCbn7E9u/Bt4St/ckldVDmAr00VR5Jf5/JCV7BXAWMIsQzH0FMCoem5eQmwt8AdgpUbdTrLupzH3tCoyL27sBxwJTBnldlNh/O/BZ4K8yvt7/MMzxcu/F9mXqBLwVeC/wnritMnJZ7+s+YHzc/hzwe+Cf4/v7HynZf0yVzwLPlvZTr80y4BngRmC3xLF5qTaPIMy1fT1hnu4fEtL3HwKOSMmeFj8bS4H/F///CFicvH4l95X1nvy+Oqc0/oLhDf+LMvV/AfyxTP1dhOnpTiBMyHFsrH8H8IdUuyPj9h2pNu5P7Z8aP6BvTNQ9Ooi+C1L7pwO/A7Zjc2O8he6DHavHQxCPN/UBr/C+FiW27wF64vZIYGFKdg3wc8KUrV+OZWVpOyF3N7BP3D4WeBA4IO7PT7W5JHnPifrdgSWpusVAT3zP1wA7xPrRyfuo5L6y3pPfV+eUxl8QZiYe7NI0mqUHe2YZ+fmJ7ceHOPYJglE5FDiDMCH+XwJnAj8t0+4k4BfAucAYUj3ihNwSoCtVd2L8IP9vou5GwgT8OybqdiT0jG9OnZ/7QxDrmvqAV3hfvyf2mOP7X/rC6S4juyswB/gq0Bvrtni/gPtS+/sAfyT05NNfMA8Sv7xT9VsTpkRM1i2M/0cAK5Kfh2rvK+s9+X11Tmn4AJ6Z3SBpT8I8oLsQfv4uA+628rO7rZd0BDAWMEmzzOyq6AfemGj3PyXdD/w9wTUxMv6/Cvi3MnosA46T9G5CL7N3EJV/RTDwNyfOvUjS08B/JuT+mtAzvFVSaWmCpwmujfen2txoZuskvQysA56L7b5YxrW3WtIUM1tE6OV2x3NGsqXPfx/Cl8to4Ewz65d0opmdWea+traYtmlmcyQtAX4Z/faWkh1JeI/SPAkk/X2V3NfHgYsl3UcwBPdI+g2wL/DvSUEzexw4VtIxwE2SziujC8ArknayMJUrZrZY0juAa4DXpmQvAO5WmH+2NAXiZMLcAj9Kyc6TdAnhdb0FuEjSDYTPRXre2kz3VcE95XFfuxI+n618X21P4TPwJO0HnE3w836GYGxPJBiCvzOz3ydkpwNmZndL2ofQC19iIV1xqGscDBwC3GVmN6aOfRK40syeKHvy5rKvI3yrTwY2EPzjl5rZCym5HxN6KqOB/ihbegjGmNn7E7L7Eibzvy9WHQiUHoJzzeySMnocQ+ilnwecbWavKSNzD3BU6UGIdZOID4KZjUnUzyZ8oZQzXJeb2X9Uel9RfgTBBVL68lxGmAFrVVrfxDm9hF87bzWzv0wdOwx4xlJLgcUBqpPN7Cup+jewKaqn1Cm42sweSMmNBI4jfEnNIfjLTyAsxPsdM3uxlvsa6p6Gua+xwCk53td04AMFuK9xlHm/2p3CG+OhkPS3ZnZh3P4ywbc8ktDTnU4wWocRPjBfSZx3l5lNj9t/B/wDoQd9BPArMzsrIfsC8CLwMHAp8Asze6aMLp8EjgJuA44EFhBcBO8hDKLdmpCt68Mdz8n1QVBYSuZohnjAK70vp3pUQSimKgjxdJpIs/0ktRQSPmTgfoLvqxdYDfTF+h629K3OT2zfzea+zfRg33yCO+AIws+8Zwi9vRMJvb3Nrh+3e4Fb4/auNHEwAphQgex2zX5Pox7Xp/Z3Ar5HWGtsO8KYwELCIgYTE3IzE9tj4/u1ELiEhC8/Hp9HGAh9TQZ93sKWET2rSEX0JK57FmHw8rlYlsS6cQm5PuA/CL96PpBq47up/W1TZTvgMWA8sG1K9ixiNAywP/AIwY/8v8Ahg7wGr83wGmwD/AthXOCF+BzcAXw45/f1/vT72iml8Bl4khYOUu4nDJCV2GBmG82sH3jYzFYDmNk6EqtaR7oUYoq3I/w6eCbKvkj4aZ3EzGzAzG40s48COwPfJbhAHknJlnzwowiDgljwoW0WR6nNY5Kf1xAxyQpxzmcpxDmfkDr23dR+On56WwaPn64kLnuapF9L+pmkyZJukrRK0t2S3pSQ20bSv0haLOkFSc9IukPSianXCUlvHqTsD0xNif+Y4MN8gmAU1xF+hfwW+H5CLulr/jqwHHg3wWj+V6rN8cA4go//LkmfkbRzWs/IdwiusmsJA1n/ZWbjCGME303JXk74RTTDzLYzs+0IkSsrCQPGJS4k/MK4grBM2RWSRsVjB6TafBa4N1HuIfxCmRe3k7zLzJ6N2+cAf21mewCHx9ek3Gvw6wyvwcWEz/s7Cb+4vgV8CHi7pFdf9xze13ex5fvaGTT72yDDt+nThDfxL1JlN+CphNydbBq9TY4Kj2XLEefHCB+sR+P/nWzTt/+ClOz8IXTrSWx/itALO5/QK/rbWL8DcFvqvMFikk8jFZNMxjjnuF9J/HQlcdlZwwv/G/gwIVLlH4EvEtZAvAj491SbG4H/iddOl3WDvQdsGVGzILE9r1z9IPtJ2YMJRvXP8fonVXD9+an9TCGOZfQpGzIZj1USillJiGclr0E68uHu0rMGLK3n+9oppekKDKtg+Kl50CDHLklsjxpEZvvkh3iYa/UCu6fq9qxA130IYWJ7DSNXSUzygtR+Mx7a+YntocILMz2wsW4RsMcguj2R2r8vsf1vg+lK8GOX4qsfYfNkmbSraovQKYKbayZwYar+DwQ31XGEn/uzYv0hbPnFlSnEkYwhk4ljWUMxM4d4Vvga/L70HBJ+bSSXGkp+yeT1vi4s10Y7l6Yr0Ikl6wMb64vw0GYyRlkf2Lh/LPD6QXSbldr/F2CbMnKvA+Yk9r+cKqWxgJ2An6TOvayC92s/wq+Z64G9gG8SfMaLgbelZMcTYmyXElwTz8f38Ksk/LsEt8dhZa41kzKZqInj7yb4av88hMwMQrz5fIIP9jrgJFLZllW8BnfF+76d2Ekh/PL7ZD3f104pTVegE0vqgX0+9cCOT8k246EdmZLLZIwI4XbDPrAJ+b0Iro5t0vdWrWw92ox1b6hAdjqb3D77EHrqRw4jtzehV7+FXBnZNxIG3rLIDnr9KnR4a1bZ1Hk/GU6mGtl2K01XwEvqDYm+5jxkCZEkU/JutxrZtBzwSUK21VUEH/4xiWNp98snsshmlatC9pOEL84ssl8mfAneQ4iWuIWQEXkbcPoQcv9TTq6SNnOQrUSHsrKEcY1k+RWwtrSfajOzbCeUpivgJfWGpHyy7SKbliP0xLeJ27vFh/xTcX9+NbL1aLNK2WFDLLPKtZos4VfWzwi/ug6J/5fH7UNSbWaW7YRSpAVJOwZJCwc7xObhei0lW0mbhJjstQBm9pikGcAcSX8R5auRrUeblcpusJDW3y9psxBLSQNVyLWa7P6EyKLTgc+Z2QJJ68zsN2xJJbJtjxvj5rAjIV5zZapehEGwVpWtpM0/S5pqZgsAzGytpKMIcyu8sUrZerRZqezLknotxLvv/+oLEFKXB6qQaylZMxsAzpP0i/j/aQaxM5XIdgTN7pp3YiFjuF6ryVbY5iQScdapYwdWI1uPNquQzRRimVWuFWVTx99FKsY8D9l2LC09N4XjOE67UPh0aMdxnE7AjbHjOE4BcGPsOI5TANwYO47jFID/D+0Lu8fG9lHmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "# sns.heatmap(C_0.T@C_0)\n",
    "a = sns.heatmap(C_0.T@C_0,cmap='CMRmap_r')\n",
    "#plt.title(\"Cora\", x=0.5, y=0.9,weight=\"bold\")\n",
    "# a.figure.savefig(\"polblogs_heatmap_03.eps\",dpi=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42a33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b688bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8371261f",
   "metadata": {},
   "source": [
    "### Plotting loss for r = 0.3,0.5,0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans is a list of 3 arrays which corresponds to loss values for FGC at r=0.3, 0.5 and 0.7. \n",
    "l3=Ans[0] # loss values for FGC at r=0.3\n",
    "l5=Ans[1] # loss values for FGC at r=0.5\n",
    "l7=Ans[2] # loss values for FGC at r=0.7\n",
    "plt.plot(np.log(l3),':',label='Coarsening ratio: 0.3')\n",
    "plt.plot(np.log(l5),'-.',label='Coarsening ratio: 0.5')\n",
    "plt.plot(np.log(l7),'--',label='Coarsening ratio: 0.7')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('log(Loss)')\n",
    "plt.savefig('final_citeseer_losscurve.eps', dpi=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9a5bc",
   "metadata": {},
   "source": [
    "### plotting top-100 eigen values curves for r=0.3,0.5,0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad89c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('X (5).npy')\n",
    "#L = np.load('L (5).npy')\n",
    "eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "#sort=eigen_values.argsort()[::-1]\n",
    "#eigen_values = eigen_values[sort] \n",
    "#print(eigen_values)\n",
    "s=np.sort(eigen_values)\n",
    "# print(s)\n",
    "#print(eigen_values.dtype)\n",
    "eigen_value,eigenvector=np.linalg.eig(C_0.T@L@C_0)\n",
    "#sorted=eigen_value.argsort()[::-1] \n",
    "#eigen_value = eigen_value[sorted]\n",
    "z=np.sort(eigen_value) \n",
    "#print(z)\n",
    "s_new=s[-100:]\n",
    "z_new=z[-100:]\n",
    "temp=0\n",
    "for j in range(len(s_new)):\n",
    "  temp=temp+(abs(z_new[j]-s_new[j])/s_new[j])\n",
    "eigenerror1=temp/len(s_new)\n",
    "print(\" eigen_error 1\")\n",
    "print(eigenerror1)\n",
    "#X = np.load('X (5).npy')\n",
    "#L = np.load('L (5).npy')\n",
    "#eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "#sort=eigen_values.argsort()[::-1]\n",
    "#eigen_values = eigen_values[sort] \n",
    "#print(eigen_values)\n",
    "#s=np.sort(eigen_values)\n",
    "#print(s)\n",
    "#print(eigen_values.dtype)\n",
    "\n",
    "\n",
    "#2\n",
    "eigen_value2,eigenvector2=np.linalg.eig(C1@L@C1.T)\n",
    "#sorted=eigen_value.argsort()[::-1] \n",
    "#eigen_value = eigen_value[sorted]\n",
    "zc2=np.sort(eigen_value2) \n",
    "#print(z)\n",
    "#s_new=s[1:100]\n",
    "zc_new2=zc2[-100:]\n",
    "temp2=0\n",
    "for j in range(len(s_new)):\n",
    "  temp2=temp2+(abs(zc_new2[j]-s_new[j])/s_new[j])\n",
    "eigenerror2=temp2/len(s_new)\n",
    "\n",
    "\n",
    "#3\n",
    "eigen_value3,eigenvector3=np.linalg.eig(C2@L@C2.T)\n",
    "#sorted=eigen_value.argsort()[::-1] \n",
    "#eigen_value = eigen_value[sorted]\n",
    "zc3=np.sort(eigen_value3) \n",
    "#print(z)\n",
    "#s_new=s[1:100]\n",
    "zc_new3=zc3[-100:]\n",
    "temp3=0\n",
    "for j in range(len(s_new)):\n",
    "  temp3=temp3+(abs(zc_new3[j]-s_new[j])/s_new[j])\n",
    "eigenerror3=temp3/len(s_new)\n",
    "\n",
    "\n",
    "\n",
    "print(\" eigen_error \")\n",
    "print(eigenerror1)\n",
    "print(eigenerror2)\n",
    "print(eigenerror3)\n",
    "plt.plot(s_new,label=\"Original\")\n",
    "plt.plot(z_new,':', label=\"FGC\")\n",
    "plt.plot(zc_new2,'-.', label=\"LVE\")\n",
    "plt.plot(zc_new3,'--', label=\"LVN\")\n",
    "plt.title(\"Citeseer\", x=0.5, y=0.9,weight=\"bold\")\n",
    "# plt.ylabel('Relative eigen-value error')\n",
    "# plt.xlabel('Nth eigenvalue')\n",
    "plt.legend()\n",
    "plt.legend()\n",
    "plt.savefig('citeseer_eigenvalues.eps', dpi=1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4bb69",
   "metadata": {},
   "source": [
    "# epsilon plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ad031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cora.\n",
    "Ans=[] # It will store loss for different coarsening ratios.\n",
    "#n=5000\n",
    "k=[270,541,812,1083,1354,1624] # [0.1*ori_nodes,0.2*ori_nodes,0.3*ori_nodes,0.4*ori_nodes,0.5*ori_nodes,0.6*ori_nodes]\n",
    "for j in k:\n",
    "    #X = np.random.multivariate_normal(np.zeros(1490), np.linalg.pinv(L), n).T\n",
    "    #k = 300\n",
    "    overall_loss = []\n",
    "    iterations = 10\n",
    "    #print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "    # Hyperparameters: lambda, beta, alpha, gamma\n",
    "    obj = solver_v2(X, j, 500, 20, 500, X.shape[1]/2) \n",
    "    C_0, X_t_0, loss_ls = obj.fit(iterations)\n",
    "    overall_loss.extend(loss_ls)\n",
    "    AA=(X-(C_0@X_t_0))\n",
    "    Ans=Ans+[np.trace((AA.T)@L@AA)/np.trace((X.T)@L@X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0.1,0.2,0.3,0.4,0.5,0.6],Ans,'o-',label='Cora',color='b')\n",
    "plt.legend(loc=\"lower left\",fontsize=8)\n",
    "plt.xlabel('Coarsening Ratio')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.savefig('Epsilon_Cora.eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e637a2",
   "metadata": {},
   "source": [
    "## Hyperbolic Error using feature matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE(u,v):\n",
    "    return np.arccosh(1+((pow(np.linalg.norm((u-v)@X),2)*pow(np.linalg.norm(X),2))/(2*np.trace(X.T@u@X)*np.trace(X.T@v@X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.linalg.pinv(C_0)\n",
    "L_lift=P.T@C_0.T@L@C_0@P\n",
    "HE(L_lift,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a42ef",
   "metadata": {},
   "source": [
    "## Reconstructional Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fd108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For cora\n",
    "p=2708 # put p = no. of nodes in the graph network. \n",
    "P=np.linalg.pinv(C_0)\n",
    "L_lift=P.T@C_0.T@L@C_0@P\n",
    "LL=(L-L_lift)\n",
    "np.log(pow(np.linalg.norm(LL),2)/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba6a0a",
   "metadata": {},
   "source": [
    "### Zachary's Karate Club dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = KarateClub()\n",
    "n_classes = len(set(np.array(dataset[0].y)))\n",
    "data = dataset[0].to(device)\n",
    "A=to_dense_adj(data.edge_index)[0]\n",
    "X=data.x  \n",
    "A=A.numpy()\n",
    "print((A!=0).sum())\n",
    "print(X)\n",
    "import numpy as np\n",
    "b=np.ones(34)\n",
    "z=A@b\n",
    "D=np.diag(z)\n",
    "L=D-A\n",
    "print(L)\n",
    "\n",
    "\n",
    "# Comment these two lines to have graph data with 4 classes.\n",
    "data.y[data.y==3]=1\n",
    "data.y[data.y==2]=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y=data.y.numpy()\n",
    "print(y)\n",
    "\n",
    "# Creating features for zachary's karate club dataset.\n",
    "\n",
    "X=np.random.multivariate_normal(np.zeros(34), np.linalg.pinv(L), 600).T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting C_0 (loading matrix), below code will classify nodes into 2 classes using C_0.  \n",
    "# Below y is a vector of actual labels of nodes in original graph G.\n",
    "import numpy\n",
    "def f(r):\n",
    "    m=max(r)\n",
    "    if(r[0]==m):\n",
    "        return 0\n",
    "    elif(r[1]==m):\n",
    "        return 1\n",
    "print(numpy.apply_along_axis(f, 1, C_0)) # Labels given by FGC.\n",
    "print(y)# Original labels.\n",
    "print(max((numpy.apply_along_axis(f, 1, C_0)==y).sum(),(numpy.apply_along_axis(f, 1, C_0)!=y).sum())) # Number of correctly classified nodes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644d60e",
   "metadata": {},
   "source": [
    "#### Effects of Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e63f3",
   "metadata": {},
   "source": [
    "Below, code for change of gamma is written. For change in alpha/lambda, place iterator 'i' inplace of that parameter. Hyperparameters for best case (gamma, alpha, lambda)=(600,500,1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d86c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below shown for BA.\n",
    "C=[]\n",
    "Xc=[]\n",
    "overall_loss = []\n",
    "for i in [100,200,300,400,500,600,700,800,900,1000,2000,5000,10000,50000]:\n",
    "    k = 700 \n",
    "    iterations = 10 \n",
    "    obj = solver_v2(X, k, i,0, 500, 1000) \n",
    "    C_0, X_t_0, loss_ls = obj.fit(iterations)\n",
    "    overall_loss.extend(loss_ls)\n",
    "    C=C+[C_0]\n",
    "    Xc=Xc+[X_t_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "I=[100,200,300,400,500,600,700,800,900,1000,2000,5000,10000,50000]\n",
    "i=0\n",
    "C_0=C_gamma[13]\n",
    "X_t_0=Xc_gamma[13]\n",
    "while(i<14):\n",
    "    eigen_values,eigenvectors=np.linalg.eig(L)\n",
    "    s=np.sort(eigen_values)\n",
    "    s_new=s[-105:-5]\n",
    "    plt.plot(s_new, label=\"Original\")\n",
    "    print(I[i])\n",
    "    eigen_value,eigenvector=np.linalg.eig(C_0.T@L@C_0)\n",
    "    z=np.sort(eigen_value) \n",
    "    z_new=z[-105:-5]\n",
    "    temp=0\n",
    "    for j in range(len(s_new)):\n",
    "      temp=temp+(abs(z_new[j]-s_new[j])/s_new[j])\n",
    "    eigenerror=temp/len(s_new)\n",
    "    print(\" eigen_error \")\n",
    "    print(eigenerror)\n",
    "    print(np.trace(X_t_0.T@C_0.T@L@C_0@X_t_0))\n",
    "    plt.plot(z_new, label=\"Coarsened\")\n",
    "    i=i+1\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a543c",
   "metadata": {},
   "source": [
    "### Graclus and Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used Graclus from torch_geometric library.\n",
    "from torch_geometric.nn import graclus\n",
    "from scipy import sparse\n",
    "Wc=sparse.csr_matrix(A)\n",
    "Wc = Wc.tocoo()\n",
    "row = torch.from_numpy(Wc.row).to(torch.long)\n",
    "col = torch.from_numpy(Wc.col).to(torch.long)\n",
    "edge_index_coarsen1 = torch.stack([row, col], dim=0)\n",
    "edge_weight = torch.from_numpy(Wc.data)\n",
    "a=graclus(edge_index_coarsen1,weight=edge_weight,num_nodes=1490)\n",
    "b = list(set(a.numpy()))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63795329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "from sklearn.cluster import KMeans\n",
    "# A is weight matrix and L is laplacian matrix of the original graph.\n",
    "dMat = np.diag(np.sum(A, axis=0))\n",
    "dMat_inv_sqrt = fractional_matrix_power(dMat, -0.5)\n",
    "laplacian_ncut = np.identity(dMat.shape[0]) - dMat_inv_sqrt @ A @ dMat_inv_sqrt\n",
    "\n",
    "def spectral_clustering(laplacian):\n",
    "    eigVals, eigVecs = np.linalg.eig(laplacian)\n",
    "    eigVals=eigVals.real \n",
    "    eigVecs=eigVecs.real\n",
    "    # find the second smallest eigenvalue\n",
    "    eigValInds = list(zip(range(eigVals.size), eigVals.tolist()))\n",
    "    eigValInds.sort(key=lambda x : x[1])\n",
    "    #print(eigValInds)\n",
    "    eigInd = eigValInds[1][0]\n",
    "    vec = eigVecs[:, eigInd].reshape((-1, 1))\n",
    "    #print(vec)\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(vec)\n",
    "    assignment = kmeans.predict(vec)\n",
    "    group1 = np.where(assignment == 0)[0] + 1\n",
    "    group2 = np.where(assignment == 1)[0] + 1\n",
    "    print('people in group 1:', group1)\n",
    "    print('people in group 2:', group2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_clustering(L)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_clustering(laplacian_ncut)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dad4a",
   "metadata": {},
   "source": [
    "You can refer this link for more details for spectral clustering code.\n",
    "https://www.alanshawn.com/jupyter-nb-show/2019/10/31/spectral-clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00111f",
   "metadata": {},
   "source": [
    "## Adversarial attack for FGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "from deeprobust.graph.data import Dataset\n",
    "dataset_name ='citeseer' #other datatsets : 'citeseer' , 'polblogs' , 'acm'\n",
    "ori_nodes =3312 #original number of nodes.\n",
    "data = Dataset(root='', name=dataset_name, setting='gcn',seed=10)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "A = np.array(adj.todense())\n",
    "X=np.array(features.todense())\n",
    "np.save(\"A.npy\", A)\n",
    "print((A!=0).sum())\n",
    "A_copy=A.copy()\n",
    "\n",
    "attack='random'\n",
    "rate=0.1 # 0.1->10%, 0.05->5%.\n",
    "from scipy import sparse\n",
    "from deeprobust.graph.data import Dataset, PrePtbDataset\n",
    "if attack == 'random':\n",
    "    from deeprobust.graph.global_attack import Random\n",
    "    import random; \n",
    "    np.random.seed(10)\n",
    "    attacker = Random()\n",
    "    A=sparse.csr_matrix(A)\n",
    "    A = A.tocoo()\n",
    "    n_perturbations = int(rate * (A.sum()//2))\n",
    "    attacker.attack(A, n_perturbations, type='add')\n",
    "    A = attacker.modified_adj\n",
    "    A=A.toarray()\n",
    "    print((A==1).sum())\n",
    "print(A.shape)\n",
    "\n",
    "\n",
    "print((A!=0).sum())\n",
    "#np.save(\"X.npy\", X)\n",
    "print(X)\n",
    "\n",
    "# Above is perturbed graph laplacian matrix.\n",
    "# Below is clean graph laplacian matrix.\n",
    "import numpy as np\n",
    "b=np.ones(ori_nodes)\n",
    "\n",
    "z=A@b\n",
    "D=np.diag(z)\n",
    "\n",
    "L=D-A\n",
    "print(L)\n",
    "\n",
    "b_copy=np.ones(ori_nodes)\n",
    "\n",
    "z_copy=A_copy@b_copy\n",
    "D_copy=np.diag(z_copy)\n",
    "\n",
    "L_copy=D_copy-A_copy\n",
    "print(L_copy)\n",
    "\n",
    "\n",
    "# Here we will obtain laplacian matrices, L_copy and L for clean and attacked graph data.\n",
    "# We will compare L_copy and Lc obtained from L in REE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7def8e",
   "metadata": {},
   "source": [
    "# GC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b09fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver_v2:\n",
    "\n",
    "  def __init__(self, k, lambda_param, beta_param, alpha_param, gamma_param):\n",
    "#     self.X = X\n",
    "#     self.p = X.shape[0]\n",
    "    self.k = k\n",
    "#     self.n = X.shape[1]\n",
    "    self.p = L.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     n = self.n\n",
    "    k = self.k\n",
    "    p = self.p\n",
    "    \n",
    "    self.thresh = 1e-10 # The 0-level\n",
    "\n",
    "    # Basic initialization (Completely random)\n",
    "#     self.X_tilde = np.random.normal(0, 1, (k, n))\n",
    "    \n",
    "    self.C = np.random.normal(0,1,(p,k))\n",
    "    self.C[self.C < self.thresh] = self.thresh\n",
    "    \n",
    "    self.w = np.random.normal(10, 1, (k*(k-1))//2)\n",
    "    self.w[self.w < self.thresh] = self.thresh\n",
    "\n",
    "\n",
    "    # Model Hyperparameters\n",
    "    self.beta_param = beta_param\n",
    "    self.alpha_param = alpha_param\n",
    "    self.lambda_param = lambda_param\n",
    "    self.gamma_param = gamma_param\n",
    "    self.iters = 0\n",
    "    self.lr0 = 1e-5\n",
    "\n",
    "  def getLR(self):\n",
    "    a = 0.99\n",
    "    return self.lr0\n",
    "\n",
    "  def calc_f(self):\n",
    "    \n",
    "    #w = self.w\n",
    "#     X_tilde = self.X_tilde\n",
    "    beta_param = self.beta_param\n",
    "    #Lw = self.L_operator(w)\n",
    "    #L = np.load('L (5).npy')\n",
    "    fw = 0\n",
    "\n",
    "#     fw += np.trace(X_tilde.T@self.C.T@L@self.C @X_tilde)\n",
    "    # Added the tr(X.T L X) term\n",
    "   # fw += ((beta_param*(np.linalg.norm(Lw)**2))/2)\n",
    "    # Added the Frobbenius norm term\n",
    "    J = np.outer(np.ones(self.k), np.ones(self.k))/self.k\n",
    "    fw -= self.gamma_param*np.linalg.slogdet(self.C.T@L@self.C + J)[1]\n",
    "    # Added the log_det term\n",
    "#     fw += (self.alpha_param/2)*(np.linalg.norm(np.subtract(self.X, np.dot(self.C, self.X_tilde))))**2\n",
    "    # Added l2 norm || X - C*X_tilde ||\n",
    "    fw += (self.lambda_param)/2*((np.linalg.norm(np.dot(self.C, np.ones((self.k, 1)))))**2)\n",
    "    # Added L_1,2 norm || C ||\n",
    "    return fw\n",
    "\n",
    "#   def update_X_tilde(self):\n",
    "#     #L = np.load('L (5).npy')\n",
    "#     L_tilde = self.C.T@L@self.C\n",
    "#     A = 2*L_tilde/(self.alpha_param)\n",
    "#     A = A + np.dot(self.C.T, self.C)\n",
    "#     b = np.dot(self.C.T, self.X)\n",
    "#     # Update 1\n",
    "#     self.X_tilde = np.linalg.pinv(A)@b\n",
    "\n",
    "#     # Update 2\n",
    "#     # lr = self.getLR()\n",
    "#     # self.X_tilde = self.X_tilde - lr*self.alpha_param*(A@self.X_tilde - b)\n",
    "\n",
    "#     # #new update:\n",
    "#     for i in range(len(self.X_tilde)):\n",
    "#       self.X_tilde[i] = (self.X_tilde[i]/(np.linalg.norm(self.X_tilde[i])))\n",
    "#     return None\n",
    "\n",
    "  def grad_C(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    J = np.outer(np.ones(k), np.ones(k))/k\n",
    "    v=np.linalg.pinv(self.C.T@L@self.C + J)\n",
    "    gradC = np.zeros(self.C.shape)\n",
    "#     gradC += self.alpha_param*((self.C@self.X_tilde - self.X)@self.X_tilde.T)\n",
    "    gradC += (self.lambda_param) * (np.abs(self.C) @ (np.ones((self.k, self.k))))\n",
    "    gradC += -2*(self.gamma_param)*L@self.C@v\n",
    "#     gradC += 2*L@self.C@self.X_tilde@self.X_tilde.T\n",
    "    \n",
    "    return gradC\n",
    "\n",
    "  def update_C(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    C = self.C\n",
    "    C = C - lr*self.grad_C()\n",
    "    C[C<self.thresh] = self.thresh\n",
    "    self.C = C\n",
    "    C = self.C.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "      C[i] = C[i]/np.linalg.norm(C[i],1)\n",
    "\n",
    "    self.C = C.copy()\n",
    "    return None\n",
    "\n",
    "  \n",
    "  def fit(self, max_iters):\n",
    "    ls = []\n",
    "    MAX_ITER_INT = 100\n",
    "    for i in tqdm(range(max_iters)):\n",
    "      #for _ in range(MAX_ITER_INT):\n",
    "        #self.update_w()\n",
    "#       for _ in range(MAX_ITER_INT):\n",
    "      self.update_C(1/self.k)\n",
    "      # for _ in range(MAX_ITER_INT):\n",
    "#       self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      #print(self.C@self.C.T)\n",
    "      #print()\n",
    "\n",
    "    return (self.C, ls )\n",
    "\n",
    "  def New_fit(self):\n",
    "    ls=[]\n",
    "    MAX_ITER_INT = 100\n",
    "    while(True):\n",
    "      C_prev=self.C\n",
    "      self.update_C(1/self.k)\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      if(np.linalg.norm(self.C-C_prev)<0.1):\n",
    "          return (self.C, ls )      \n",
    "    return (self.C, ls )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below shown for Cora.\n",
    "k = 750 # Coarsened graph's number of nodes i.e. k = r*ori_nodes\n",
    "overall_loss = []\n",
    "iterations = 100 # Number of iterations our objective function will run.\n",
    "#print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "# Hyperparameters: lambda, beta, alpha, gamma\n",
    "# Only lambda and gamma hyperparameters are used. So you can ignore beta and alpha.\n",
    "obj = solver_v2( k, 300, 0, 0, 250) \n",
    "C_0, loss_ls = obj.fit(iterations)\n",
    "overall_loss.extend(loss_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86407155",
   "metadata": {},
   "source": [
    "Hyperbolic error for GC on graph datasets having no features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "E=np.linalg.eig(L)\n",
    "eigen_values,eigenvectors=E\n",
    "D={}\n",
    "# N is the number of nodes in the graph. \n",
    "for c in range(N):\n",
    "    D[eigen_values[c]]=eigenvectors[c]\n",
    "# print(len(D))\n",
    "D=dict(sorted(D.items(), key=lambda item: item[0]))\n",
    "EV=D.values()\n",
    "ev=D.keys()\n",
    "ev=np.array(list(ev))\n",
    "EV=np.array(list(EV))\n",
    "ev[ev<1e-5]=0\n",
    "ind=np.argmax(ev==ev[ev!=0][0])\n",
    "x=EV[ind]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HE(u,v):\n",
    "    return np.arccosh(1+((pow(np.linalg.norm((u-v)@x),2)*pow(np.linalg.norm(x),2))/(2*(x.T@u@x)*(x.T@v@x))))\n",
    "# Above x is eigen vector corresponding to smallest non-zero eigen value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c9fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051be53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a8018f",
   "metadata": {},
   "source": [
    "## Two stage featured graph coarsening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tilda=np.linalg.pinv(C_0)@X\n",
    "Lc=C_0.T@L@C_0\n",
    "Xc=np.linalg.pinv(np.eye(Lc.shape[0])+Lc)@X_tilda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d04ca7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3cfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ed91f71",
   "metadata": {},
   "source": [
    "# FGCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68944b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class solver_v2:\n",
    "\n",
    "  def __init__(self, X, k,d, lambda_param, beta_param, alpha_param, gamma_param):\n",
    "    self.X = X\n",
    "    self.p = X.shape[0]\n",
    "    self.n = X.shape[1]\n",
    "    self.k = k\n",
    "    self.d = d\n",
    "    \n",
    "    p = self.p    \n",
    "    n = self.n\n",
    "    k = self.k\n",
    "    d = self.d\n",
    "\n",
    "    \n",
    "    self.thresh = 1e-10 # The 0-level\n",
    "\n",
    "    # Basic initialization (Completely random)\n",
    "#     self.X_tilde = np.random.normal(0, 1, (k, n))\n",
    "    self.W = np.random.normal(0, 1, (k, d))\n",
    "    self.H = np.random.normal(0, 1, (d, n))\n",
    "    \n",
    "    self.C = np.random.normal(0,1,(p,k))\n",
    "    self.C[self.C < self.thresh] = self.thresh\n",
    "    \n",
    "    self.w = np.random.normal(10, 1, (k*(k-1))//2)\n",
    "    self.w[self.w < self.thresh] = self.thresh\n",
    "    \n",
    "\n",
    "    # Model Hyperparameters\n",
    "    self.beta_param = beta_param\n",
    "    self.alpha_param = alpha_param\n",
    "    self.lambda_param = lambda_param\n",
    "    self.gamma_param = gamma_param\n",
    "    self.iters = 0\n",
    "    self.lr0 = 1e-5\n",
    "\n",
    "  def getLR(self):\n",
    "    a = 0.99\n",
    "    return self.lr0\n",
    "\n",
    "  def calc_f(self):\n",
    "    \n",
    "    #w = self.w\n",
    "#     X_tilde = self.X_tilde\n",
    "    W=self.W\n",
    "    H=self.H\n",
    "    beta_param = self.beta_param\n",
    "    #Lw = self.L_operator(w)\n",
    "    #L = np.load('L (5).npy')\n",
    "    fw = 0\n",
    "\n",
    "    fw += np.trace(W.T@self.C.T@L@self.C @W)\n",
    "    # Added the tr(X.T L X) term\n",
    "   # fw += ((beta_param*(np.linalg.norm(Lw)**2))/2)\n",
    "    # Added the Frobbenius norm term\n",
    "    J = np.outer(np.ones(self.k), np.ones(self.k))/self.k\n",
    "    fw -= self.gamma_param*np.linalg.slogdet(self.C.T@L@self.C + J)[1]\n",
    "    # Added the log_det term\n",
    "    fw += (self.alpha_param/2)*(np.linalg.norm(np.subtract(self.X, np.dot(self.C, np.dot(W,H)))))**2\n",
    "    # Added l2 norm || X - C*X_tilde ||\n",
    "    fw += (self.lambda_param)/2*((np.linalg.norm(np.dot(self.C, np.ones((self.k, 1)))))**2)\n",
    "    # Added L_1,2 norm || C ||\n",
    "    fw += ((beta_param*((np.linalg.norm(W)**2)+(np.linalg.norm(H)**2)))/2)\n",
    "    # Added Frobbenius norm terms\n",
    "    return fw\n",
    "\n",
    "  def update_X_tilde(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    L_tilde = self.C.T@L@self.C\n",
    "    A = 2*L_tilde/(self.alpha_param)\n",
    "    A = A + np.dot(self.C.T, self.C)\n",
    "    b = np.dot(self.C.T, self.X)\n",
    "    # Update 1\n",
    "    self.X_tilde = np.linalg.pinv(A)@b\n",
    "\n",
    "    # Update 2\n",
    "    # lr = self.getLR()\n",
    "    # self.X_tilde = self.X_tilde - lr*self.alpha_param*(A@self.X_tilde - b)\n",
    "\n",
    "    # #new update:\n",
    "    for i in range(len(self.X_tilde)):\n",
    "      self.X_tilde[i] = (self.X_tilde[i]/(np.linalg.norm(self.X_tilde[i])))\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "  def grad_C(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    J = np.outer(np.ones(k), np.ones(k))/k\n",
    "    v=np.linalg.pinv(self.C.T@L@self.C + J)\n",
    "    gradC = np.zeros(self.C.shape)\n",
    "    gradC += self.alpha_param*((self.C@self.W@self.H - self.X)@self.H.T@self.W.T)\n",
    "    gradC += (self.lambda_param) * (np.abs(self.C) @ (np.ones((self.k, self.k))))\n",
    "    gradC += -2*(self.gamma_param)*L@self.C@v\n",
    "    gradC += 2*L@self.C@self.W@self.W.T\n",
    "    \n",
    "    return gradC\n",
    "\n",
    "  def update_C(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    C = self.C\n",
    "    C = C - lr*self.grad_C()\n",
    "    C[C<self.thresh] = self.thresh\n",
    "    self.C = C\n",
    "    C = self.C.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "      C[i] = C[i]/np.linalg.norm(C[i],1)\n",
    "\n",
    "    self.C = C.copy()\n",
    "    return None\n",
    "\n",
    "\n",
    "  def grad_W(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    gradW = np.zeros(self.W.shape)\n",
    "    gradW -= self.alpha_param*(self.C.T@(self.C@self.W@self.H-self.X)@self.H.T)\n",
    "    gradW += 2*(self.C.T@L@self.C@self.W)\n",
    "    gradW += self.beta_param*self.W\n",
    "    return gradW\n",
    "\n",
    "  def update_W(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    W = self.W\n",
    "    W = W - lr*self.grad_W()\n",
    "    W[W<self.thresh] = self.thresh\n",
    "    self.W = W\n",
    "    W = self.W.copy()\n",
    "\n",
    "    for i in range(len(W)):\n",
    "      W[i] = W[i]/np.linalg.norm(W[i],1)\n",
    "\n",
    "    self.W = W.copy()\n",
    "    return None\n",
    "\n",
    "  def grad_H(self):\n",
    "    #L = np.load('L (5).npy')\n",
    "    gradH = np.zeros(self.H.shape)\n",
    "    gradH -= self.alpha_param*(self.W.T@self.C.T@(self.C@self.W@self.H-self.X))\n",
    "    gradH += self.beta_param*self.H\n",
    "    return gradH\n",
    "\n",
    "  def update_H(self, lr = None):\n",
    "    if not lr:\n",
    "      lr = 1/ (self.k)\n",
    "    lr = self.getLR()\n",
    "    H = self.H\n",
    "    H = H - lr*self.grad_H()\n",
    "    H[H<self.thresh] = self.thresh\n",
    "    self.H = H\n",
    "    H = self.H.copy()\n",
    "\n",
    "    for i in range(len(H)):\n",
    "      H[i] = H[i]/np.linalg.norm(H[i],1)\n",
    "\n",
    "    self.H = H.copy()\n",
    "    return None\n",
    "  \n",
    "  def fit(self, max_iters):\n",
    "    ls = []\n",
    "    MAX_ITER_INT = 200\n",
    "    for i in tqdm(range(max_iters)):\n",
    "      #for _ in range(MAX_ITER_INT):\n",
    "        #self.update_w()\n",
    "      for _ in range(MAX_ITER_INT):\n",
    "        self.update_C(1/self.k)\n",
    "        self.update_W(1/self.k)\n",
    "        self.update_H(1/self.k)\n",
    "      # for _ in range(MAX_ITER_INT):\n",
    "#       self.update_X_tilde()\n",
    "      ls.append(self.calc_f())\n",
    "      self.iters+=1\n",
    "      #print(self.C@self.C.T)\n",
    "      #print()\n",
    "\n",
    "    return (self.C, self.W, self.H, ls )\n",
    "\n",
    "#   def New_fit(self):\n",
    "#     ls=[]\n",
    "#     MAX_ITER_INT = 100\n",
    "#     while(True):\n",
    "#       C_prev=self.C\n",
    "#       self.update_C(1/self.k)\n",
    "#       self.update_X_tilde()\n",
    "#       ls.append(self.calc_f())\n",
    "#       self.iters+=1\n",
    "#       if(np.linalg.norm(self.C-C_prev)<0.1):\n",
    "#           return (self.C, self.X_tilde, ls )      \n",
    "#     return (self.C, self.X_tilde, ls )    \n",
    "\n",
    "  def set_experiment(self, X, X_t):\n",
    "    self.X = X\n",
    "    self.X_tilde = X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below shown for Cora.\n",
    "k = 812 # Coarsened graph's number of nodes i.e. k = r*ori_nodes\n",
    "d= 429 # Reduced number of features in coarsened graph\n",
    "overall_loss = []\n",
    "iterations = 5 # Number of iterations our objective function will run.\n",
    "#print(\"Shape of the data matrix (p x n): \", X_now.shape)\n",
    "\n",
    "# Hyperparameters: lambda, beta, alpha, gamma\n",
    "obj = solver_v2(X,k,d, 400, 20, 800, 700) \n",
    "C_0, W_0,H_0, loss_ls = obj.fit(iterations) # W_0 is feature matrix of coarsened graph\n",
    "overall_loss.extend(loss_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb74e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
